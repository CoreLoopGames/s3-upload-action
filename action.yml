name: 'Upload to S3 using AWS CLI'
description: 'Upload files or directories to an S3 bucket using the AWS CLI.'

inputs:
  aws-access-key-id:
    description: 'AWS Access Key ID'
    required: true
  aws-secret-access-key:
    description: 'AWS Secret Access Key'
    required: true
  aws-region:
    description: 'AWS Region'
    required: true
    default: 'us-east-1'
  s3-bucket:
    description: 'S3 Bucket Name'
    required: true
  local-path:
    description: 'Comma-separated list of local paths to upload'
    required: true
  s3-key:
    description: 'Comma-separated list of S3 keys (paths) to upload to'
    required: true
  zip-before-upload:
    description: 'Whether to zip the directory before uploading. Set to `true` or `false`.'
    required: false
    default: 'false'

runs:
  using: 'composite'
  steps:
    - name: Configure AWS CLI
      shell: bash
      env:
        AWS_ACCESS_KEY_ID: ${{ inputs.aws-access-key-id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws-secret-access-key }}
        AWS_DEFAULT_REGION: ${{ inputs.aws-region }}
      run: |
        aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
        aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
        aws configure set region $AWS_DEFAULT_REGION
        
    - name: Upload multiple files/directories to S3
      shell: bash
      run: |
        IFS=',' read -ra LOCAL_PATHS <<< "${{ inputs.local-path }}"
        IFS=',' read -ra S3_KEYS <<< "${{ inputs.s3-key }}"

        if [ "${#LOCAL_PATHS[@]}" -ne "${#S3_KEYS[@]}" ]; then
          echo "Error: The number of local paths and S3 keys must be the same."
          exit 1
        fi

        for i in "${!LOCAL_PATHS[@]}"; do
          LOCAL_PATH="${LOCAL_PATHS[$i]}"
          S3_KEY="${S3_KEYS[$i]}"

          echo "Processing: Local='${LOCAL_PATH}' -> S3 Key='${S3_KEY}'"

          if [[ "${{ inputs.zip-before-upload }}" == "true" ]]; then
            ZIP_NAME="upload_${i}.zip"
            echo "Zipping '${LOCAL_PATH}' into '${ZIP_NAME}'"
            zip -r "${ZIP_NAME}" "${LOCAL_PATH}"
            aws s3 cp "${ZIP_NAME}" "s3://${{ inputs.s3-bucket }}/${S3_KEY}"
            rm -f "${ZIP_NAME}"
          else
            if [[ -d "${LOCAL_PATH}" ]]; then
              # For directories, use --recursive and ensure S3 key ends with /
              aws s3 cp "${LOCAL_PATH}" "s3://${{ inputs.s3-bucket }}/${S3_KEY}/" --recursive
            else
              aws s3 cp "${LOCAL_PATH}" "s3://${{ inputs.s3-bucket }}/${S3_KEY}"
            fi
          fi
        done
